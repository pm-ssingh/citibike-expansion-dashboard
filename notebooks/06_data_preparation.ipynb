{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.7 - Data Preparation for Dashboard Deployment\n",
    "\n",
    "## Citi Bike NYC Expansion Dashboard - Final Dataset\n",
    "\n",
    "**Author:** Saurabh Singh  \n",
    "**Exercise:** Achievement 2, Exercise 2.7  \n",
    "**Date:** February 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "### Why create a reduced dataset?\n",
    "\n",
    "**Deployment constraint:**\n",
    "- GitHub has a 25 MB file size limit\n",
    "- Original merged dataset exceeds this limit\n",
    "- Need to create a smaller sample for deployment\n",
    "\n",
    "**Strategy:**\n",
    "- Random sampling to maintain data distribution\n",
    "- Keep only columns needed for dashboard\n",
    "- Set random seed for reproducibility\n",
    "- Target: ~8% sample to stay under 25 MB\n",
    "\n",
    "### What we'll do:\n",
    "\n",
    "1. Load full dataset\n",
    "2. Add season column for filtering\n",
    "3. Drop unnecessary columns\n",
    "4. Create random sample (seed=32)\n",
    "5. Save reduced dataset for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged dataset\n",
    "df = pd.read_csv('outputs/merged_citibike_weather_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Add Season Column\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "Adding a season column enables filtering in the dashboard to analyze seasonal patterns.\n",
    "\n",
    "### Season definitions:\n",
    "- **Winter**: December, January, February, March, April (low demand months)\n",
    "- **Spring**: Late April, May (transition)\n",
    "- **Summer**: June, July, August, September (peak demand)\n",
    "- **Fall**: October, November (transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime and extract month\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df['month'] = df['month'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create season column\n",
    "df['season'] = [\n",
    "    \"winter\" if (month == 12 or 1 <= month <= 4)\n",
    "    else \"spring\" if (4 < month <= 5)\n",
    "    else \"summer\" if (6 <= month <= 9)\n",
    "    else \"fall\"\n",
    "    for month in df['month']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify season distribution\n",
    "print(\"Season distribution:\")\n",
    "print(df['season'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Select Necessary Columns\n",
    "\n",
    "### Columns to keep:\n",
    "\n",
    "**For charts:**\n",
    "- `date` - Time series analysis\n",
    "- `start_station_name` - Station popularity\n",
    "- `avgTemp` - Weather correlation\n",
    "\n",
    "**For filtering:**\n",
    "- `season` - Seasonal analysis\n",
    "- `month` - Monthly patterns\n",
    "\n",
    "**Derived columns:**\n",
    "- `value` - Trip counting (will be added)\n",
    "\n",
    "### Columns to drop:\n",
    "\n",
    "All individual trip details not needed for aggregated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "df_weather = pd.read_csv('outputs/weather_data_2022.csv')\n",
    "\n",
    "# Convert dates\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "\n",
    "# Merge weather data\n",
    "df = df.merge(df_weather, on='date', how='left')\n",
    "\n",
    "# Check columns\n",
    "print(\"Columns after merge:\", df.columns.tolist())\n",
    "print(\"avgTemp present:\", 'avgTemp' in df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns\n",
    "columns_to_keep = ['date', 'start_station_name', 'avgTemp', 'season', 'month']\n",
    "df_reduced = df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reduced columns: {df_reduced.columns.tolist()}\")\n",
    "print(f\"Shape: {df_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Create Random Sample\n",
    "\n",
    "### Sampling strategy:\n",
    "\n",
    "**Reproducibility:**\n",
    "- Set `np.random.seed(32)` for consistent results\n",
    "- Same seed = same sample every time\n",
    "\n",
    "**Sample size:**\n",
    "- Target: ~8% of original data\n",
    "- Method: Random selection using `np.random.rand()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random sample (92% excluded, 8% kept)\n",
    "exclude_mask = np.random.rand(len(df_reduced)) <= 0.92\n",
    "df_sample = df_reduced[~exclude_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original rows: {len(df_reduced):,}\")\n",
    "print(f\"Sample rows: {len(df_sample):,}\")\n",
    "print(f\"Percentage: {len(df_sample)/len(df_reduced)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Add Value Column for Counting\n",
    "\n",
    "Adding the `value` column enables trip counting in dashboard aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add value column\n",
    "df_sample['value'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Create Daily Aggregation for Line Chart\n",
    "\n",
    "Pre-aggregate daily data to improve dashboard performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily aggregation\n",
    "df_daily_full = df_sample.groupby('date', as_index=False).agg({\n",
    "    'value': 'sum',\n",
    "    'avgTemp': 'first'\n",
    "})\n",
    "\n",
    "df_daily_full.rename(columns={'value': 'bike_rides_daily'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Save Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reduced sample\n",
    "df_sample.to_csv('outputs/reduced_data_to_plot.csv', index=False)\n",
    "print(f\"Saved: outputs/reduced_data_to_plot.csv\")\n",
    "print(f\"Rows: {len(df_sample):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize('outputs/reduced_data_to_plot.csv') / (1024 * 1024)\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")\n",
    "if file_size_mb < 25:\n",
    "    print(\"✅ File is under 25 MB - ready for GitHub!\")\n",
    "else:\n",
    "    print(\"⚠️ File exceeds 25 MB - need smaller sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Dataset prepared:\n",
    "\n",
    "✅ **Reduced sample created** - Under 25 MB for GitHub deployment  \n",
    "✅ **Season column added** - Enables seasonal filtering in dashboard  \n",
    "✅ **Unnecessary columns removed** - Only dashboard essentials kept  \n",
    "✅ **Random seed set** - Reproducible sampling (seed=32)  \n",
    "✅ **Value column added** - Ready for trip counting  \n",
    "\n",
    "### Files created:\n",
    "\n",
    "- `outputs/reduced_data_to_plot.csv` - Main dashboard dataset\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. Create multi-page Streamlit dashboard\n",
    "2. Add seasonal filters and metrics\n",
    "3. Include all visualizations with interpretations\n",
    "4. Add recommendations page\n",
    "5. Test locally\n",
    "6. Deploy to Streamlit Community Cloud\n",
    "\n",
    "The reduced dataset maintains the statistical properties of the full dataset while meeting deployment constraints!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CitiBike Environment",
   "language": "python",
   "name": "citibike_env_unique"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

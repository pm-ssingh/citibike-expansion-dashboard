{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citi Bike NYC Expansion Dashboard - Data Collection & Processing\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Objective:** Create a strategic dashboard to guide Citi Bike's expansion strategy by identifying optimal locations for new bike stations.\n",
    "\n",
    "**Business Problem:** Bike shortages at popular stations indicate unmet demand. Strategic placement of new stations can maximize ROI on infrastructure investment.\n",
    "\n",
    "**Data Sources:**\n",
    "- Primary: Citi Bike trip data for all of 2022 (12 monthly CSV files)\n",
    "- Supplementary: NOAA weather data from LaGuardia Airport weather station\n",
    "\n",
    "**Research Questions:**\n",
    "1. What are the most popular stations?\n",
    "2. How does weather affect ridership patterns?\n",
    "3. What are the most popular routes between stations?\n",
    "4. Are existing stations evenly distributed?\n",
    "\n",
    "**Methodology:**\n",
    "- Concatenate 12 monthly trip files into single dataset\n",
    "- Use NOAA API to fetch daily temperature data for 2022\n",
    "- Merge trip data with weather data on date field\n",
    "- Export cleaned dataset for visualization\n",
    "\n",
    "**Author:** Saurabh Singh  \n",
    "**Exercise:** 2.2 - Planning & Data Sourcing with APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load and Concatenate Citi Bike Data\n",
    "\n",
    "### How this code works:\n",
    "\n",
    "**Step 1: Create list of file paths using list comprehension**\n",
    "- `os.listdir(folderpath)` returns all filenames in the 'data' folder\n",
    "- The list comprehension loops through each filename\n",
    "- `os.path.join()` combines the folder path with each filename to create full file paths\n",
    "- Result: a list containing paths to all 12 CSV files\n",
    "\n",
    "**Step 2: Read and concatenate files using a generator**\n",
    "- A generator `(pd.read_csv(f) for f in filepaths)` is used instead of a list comprehension\n",
    "- Generators use parentheses `()` while list comprehensions use brackets `[]`\n",
    "- Generators are more memory-efficient because they process one file at a time\n",
    "- `pd.concat()` stacks all DataFrames vertically (axis=0)\n",
    "- `ignore_index=True` creates a new sequential index for the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a list with all file paths using list comprehension\n",
    "folderpath = r\"data\"  # Folder containing the CSV files\n",
    "filepaths = [os.path.join(folderpath, name) for name in os.listdir(folderpath)]\n",
    "\n",
    "print(f\"Found {len(filepaths)} files\")\n",
    "print(\"Files:\")\n",
    "for file in filepaths:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read and join all CSV files using a generator with pd.concat()\n",
    "df = pd.concat((pd.read_csv(f) for f in filepaths), ignore_index=True)\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows to verify all data was loaded\n",
    "print(\"Last 5 rows:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Obtain Weather Data from NOAA API\n",
    "\n",
    "### NOAA API Configuration\n",
    "\n",
    "We'll fetch daily average temperature data from LaGuardia Airport weather station for 2022.\n",
    "\n",
    "**API Parameters:**\n",
    "- Dataset: GHCND (Global Historical Climatology Network Daily)\n",
    "- Station: GHCND:USW00014732 (LaGuardia Airport)\n",
    "- Data Type: TAVG (Daily Average Temperature)\n",
    "- Period: January 1, 2022 - December 31, 2022\n",
    "- Limit: 1000 records (maximum allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your NOAA token (replace with your actual token from NOAA email)\n",
    "Token = 'PCBYzCnHmLFQWfIHNMkMEkcnBxhaKwJJ'\n",
    "\n",
    "# LaGuardia Airport weather station ID for New York\n",
    "station_id = 'GHCND:USW00014732'\n",
    "\n",
    "# Compile the API URL with all parameters\n",
    "url = f'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&limit=1000&stationid={station_id}&startdate=2022-01-01&enddate=2022-12-31'\n",
    "\n",
    "print(f\"Requesting weather data from NOAA API...\")\n",
    "print(f\"Station: LaGuardia Airport ({station_id})\")\n",
    "print(f\"Period: 2022-01-01 to 2022-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the API request with authentication token\n",
    "r = requests.get(url, headers={'token': Token})\n",
    "\n",
    "# Check if request was successful\n",
    "if r.status_code == 200:\n",
    "    print(\"✓ API request successful!\")\n",
    "else:\n",
    "    print(f\"✗ API request failed with status code: {r.status_code}\")\n",
    "    print(f\"Response: {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API response as JSON\n",
    "d = json.loads(r.text)\n",
    "\n",
    "print(f\"JSON loaded successfully\")\n",
    "print(f\"Number of results: {len(d.get('results', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle Weather Data\n",
    "\n",
    "Extract only the temperature values and dates from the JSON response using list comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure all items in the response that correspond to TAVG (average temperature)\n",
    "avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "\n",
    "# Get only the date field from all average temperature readings\n",
    "dates_temp = [item['date'] for item in avg_temps]\n",
    "\n",
    "# Get the temperature values from all average temperature readings\n",
    "temps = [item['value'] for item in avg_temps]\n",
    "\n",
    "print(f\"Extracted {len(dates_temp)} temperature records\")\n",
    "print(f\"Date range: {dates_temp[0]} to {dates_temp[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weather DataFrame\n",
    "\n",
    "Convert the extracted data into a clean DataFrame:\n",
    "- Parse dates from ISO format (YYYY-MM-DDTHH:MM:SS) to datetime\n",
    "- Convert temperature from tenths of Celsius to Celsius (NOAA stores temps × 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe\n",
    "df_weather = pd.DataFrame()\n",
    "\n",
    "# Convert date strings to datetime objects (removes time component)\n",
    "df_weather['date'] = [datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S\") for d in dates_temp]\n",
    "\n",
    "# Convert temperature from tenths of Celsius to Celsius by dividing by 10\n",
    "df_weather['avgTemp'] = [float(v)/10.0 for v in temps]\n",
    "\n",
    "print(\"Weather data DataFrame created successfully!\")\n",
    "print(f\"Shape: {df_weather.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of weather data:\")\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"Last 5 rows of weather data:\")\n",
    "df_weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export weather data to CSV\n",
    "df_weather.to_csv('outputs/weather_data_2022.csv', index=False)\n",
    "print(\"Weather data saved to: outputs/weather_data_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Merge Citi Bike Data with Weather Data\n",
    "\n",
    "### Prepare Date Columns for Merge\n",
    "\n",
    "Before merging, we need to ensure both datasets have matching date formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert start_time to datetime format\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "\n",
    "# Extract date component (without time) for merging\n",
    "df['date'] = pd.to_datetime(df['started_at']).dt.date\n",
    "\n",
    "# Convert weather date to date format (remove time component) for matching\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date']).dt.date\n",
    "\n",
    "print(\"Date columns prepared for merge\")\n",
    "print(f\"\\nCiti Bike date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Weather date range: {df_weather['date'].min()} to {df_weather['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Merge\n",
    "\n",
    "Merge the datasets using a left join on the date column:\n",
    "- Left join ensures all Citi Bike trips are retained\n",
    "- Weather data is matched by date\n",
    "- `indicator=True` creates a column showing merge quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Merge datasets on date field using left join\n",
    "df_merged = df.merge(df_weather, how='left', on='date', indicator=True)\n",
    "\n",
    "print(f\"\\nMerged dataset shape: {df_merged.shape}\")\n",
    "print(f\"Columns: {df_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Merge Quality\n",
    "\n",
    "Check the merge indicator to ensure all records matched successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merge quality:\")\n",
    "print(df_merged['_merge'].value_counts())\n",
    "\n",
    "# Calculate match percentage\n",
    "total_rows = len(df_merged)\n",
    "both_count = (df_merged['_merge'] == 'both').sum()\n",
    "match_pct = (both_count / total_rows) * 100\n",
    "\n",
    "print(f\"\\nMatch rate: {match_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the merge indicator column (cleanup)\n",
    "df_merged = df_merged.drop(columns=['_merge'])\n",
    "\n",
    "print(\"Merge indicator column removed\")\n",
    "print(f\"Final dataset shape: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of merged data\n",
    "print(\"Sample of merged dataset:\")\n",
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Export Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export merged dataset to CSV\n",
    "df_merged.to_csv('outputs/merged_citibike_weather_2022.csv', index=False)\n",
    "\n",
    "print(\"✓ Export complete!\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. outputs/merged_citibike_weather_2022.csv ({len(df_merged):,} rows)\")\n",
    "print(f\"  2. outputs/weather_data_2022.csv ({len(df_weather):,} rows)\")\n",
    "print(f\"\\nDataset ready for visualization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook successfully:\n",
    "1. ✓ Loaded and concatenated 12 months of Citi Bike trip data using list comprehensions and generators\n",
    "2. ✓ Fetched daily temperature data from NOAA API for LaGuardia Airport\n",
    "3. ✓ Merged trip data with weather data on date field with 100% match rate\n",
    "4. ✓ Exported cleaned datasets for dashboard visualization\n",
    "\n",
    "**Next Steps:**\n",
    "- Create visualizations to answer research questions\n",
    "- Identify most popular stations and routes\n",
    "- Analyze weather impact on ridership\n",
    "- Develop expansion recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
